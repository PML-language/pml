The notion of computation, or evaluation, is at the heart of the (classical)
realizability techniques that are used for the formal definition of the \pml
language. In this chapter, we give the syntax and the operational semantics
of the language as a pure, untyped, calculus. It will be expressed using a
\emph{Krivine Abstract Machine}, which will allow us to account for control
operators, as well as observational equivalence of programs.\footnote{This
notion of program equivalence will play an very important role as it will be
partially reflected in the type system of the language through ``equivalence
types''.}

\section{Syntax of the abstract machine}

The abstract machine we will consider has the peculiarity of having a
call-by-value reduction strategy, which requires a syntax formed with four
entities: values, terms, stacks and processes. Note that the distinction
between terms and values is specific to our call-by-value presentation, they
would be collapsed in call-by-name.
\begin{definition}[variables]
  We require three disjoint, countable sets of variables $\mathcal{V}_{ι}$,
  $\mathcal{V}_{σ}$ and $\mathcal{V}_{τ}$ for $λ$-variables, $μ$-variables
  and terms variables respectively.
  $$
    \mathcal{V}_{ι} = \{x, y, z ...\}
    \quad\quad\quad
    \mathcal{V}_{σ} = \{α, β, γ ...\}
    \quad\quad\quad
    \mathcal{V}_{τ} = \{a, b, c ...\}
  $$
\end{definition}
As usual, $λ$-variables and $μ$-variables will be bound in terms to
respectively form functions and capture continuations. Term variables
are intended to be substituted by (unevaluated) terms, and not only
values. They will be bound by our fixpoint operator in terms, and they
will also be bound by quantifiers in formulas to express properties
ranging over the set of all terms.

\begin{figure}
  \begin{align*}
    (Λ_{ι})\quad\quad \makebox[1.8em]{v,w}
      \bnfeq &x                     \tag{$λ$-variable}\\
      \bnfor &λx.t                  \tag{$λ$-abstraction}\\
      \bnfor &C_k[v]                \tag{constructor, $k∈\mathbb{N}$}\\
      \bnfor &\{(l_i = v_i)_{i∈I}\}
                            \tag{record, $I ⊆_\text{fin} \mathbb{N}$}\\
      \bnfor &\square               \tag{box, invalid value}\\[10pt]
    (Λ)\quad\quad \makebox[1.8em]{t,u}
      \bnfeq &a                     \tag{term variable}\\
      \bnfor &v                     \tag{value as a term}\\
      \bnfor &t\,u                  \tag{application}\\
      \bnfor &μα.t                  \tag{$μ$-abstraction}\\
      \bnfor &[π]t                  \tag{named term}\\
      \bnfor &v.l_k                 \tag{record projection, $k∈\mathbb{N}$}\\
      \bnfor &[v\,| (C_i[x_i] → t_i)_{i∈I}]
                            \tag{case analysis, $I ⊆_\text{fin} \mathbb{N}$}\\
      \bnfor &φa.v                  \tag{fixpoint}\\
      \bnfor &R(v,t)                \tag{special instruction}\\
      \bnfor &δ(v,w,t)              \tag{special instruction}\\[10pt]
    (Π)\quad\quad \makebox[1.8em]{π,ξ}
      \bnfeq &ε                     \tag{empty stack}\\
      \bnfor &α                     \tag{$μ$-variable}\\
      \bnfor &[{-}\;v]π             \tag{pushed argument}\\
      \bnfor &[t\;\,{-}]π           \tag{pushed function}\\[10pt]
    (Λ \times Π)\quad\quad \makebox[1.8em]{p,q}
      \bnfeq &t∗π                   \tag{processe}
  \end{align*}
  \caption{Syntax of the untyped calculus.}
  \label{fig:untyped_syntax}
\end{figure}

\begin{definition}[untyped calculus]
  Values, terms, stacks and processes are mutually inductively defined by the
  \emph{BNF grammar} of Figure~\ref{fig:untyped_syntax}. The names of the
  corresponding sets are displayed on the left: $(Λ_{ι})$ for values, $(Λ)$
  for terms, $(Π)$ for stacks, and $(Λ \times Π)$ for processes.
\end{definition}

Terms and values form a variation of the $λμ$-calculus \cite{Parigot1992},
enriched with records, variants and a fixpoint operator. Values of the form
$C_k[v]$ (where $k ∈ \mathbb{N}$) correspond to variants, or constructors.
Note that they always have exactly one argument in our language. Case analysis
on variants is performed using the syntax $[v\,| (C_i[x_i] → t_i)_{i∈I}]$,
where the pattern $C_i[x_i]$ is mapped to the term $t_i$ for all index $i$ in
the finite set $I$. Similarly, values of the form $\{(l_i = v_i)_{i∈I}\}$
correspond to records, which are tuples with named fields. The projection
operation $v.l_k$ can be used to access the value labelled $l_k$ in a record
$v$.
\begin{remark}
  The syntax $[v\,| (C_i[x_i] → t_i)_{i∈I}]$ for case analyses and the syntax
  $\{(l_i = v_i)_{i∈I}\}$ for records are part of our meta-language. We only
  use them as a short notation for arbitrary lists of patterns or record
  fields. In the language, the full list of patterns or fields always needs
  to be specified. We would thus, for example, write $\{l_1=v_1; l_2=v_2\}$ or
  $[v\,| C_1[x_1] → t_1 | C_2[x_2] → t_2]$ in the case where $I = \{1, 2\}$.
\end{remark}
Terms of the form $φa.v$ denote a fixpoint, which can be used for general
recursion. They roughly corresponds to the \verb#let rec# construct of the
OCaml language. However, binding a term in a value will allow us to encode
mutually recursive functions with records.
%
The value $\square$ and terms of form $R(v,t)$ or $δ(v,w,t)$ are only
included for a technical purpose. In particular, they are not intended
to be used for programming. The value $\square$ will be used in the
definition of our semantics, terms of the form $R(v,t)$ will allow us
to distinguish records from other sorts of values in our definition of
observational equivalence, and terms of the form $δ(v,w,t)$ will be
used to ensure that our model has an essential property (again related
to equivalence).

\begin{remark}
  We enforce values in constructors, record fields, projections and case
  analyses. This makes the calculus simpler because only $β$-reduction
  will need to manipulate the stack. Syntactic sugar such as the following
  can be defined to hide these restrictions to the user.
  $$
    t.l_k := (λx.x.l_k)\,t
    \quad\quad\quad\quad
    C_k[t] := (λx.C_k[x])\,t
  $$
  The elimination of such syntactic sugar corresponds to a form of partial
  \verb#let#-normalization \cite{Moggi1989} or \verb#A#-normalization
  \cite{Flanagan1993}. The translation can hence be seen as a natural
  compilation step \cite{Tarditi1996, Chlipala2005}.
\end{remark}

\section{Substitution and base evaluation}

We will now define a first evaluation relation of our calculus, that will
then be extended in the next section. Before going into reduction, we first
need to define the notions of free variables and substitutions. Although
they are fairly usual, these definitions introduce our notations.

\begin{definition}[free variables and closed expression]
  Given a value, term, stack or process $ψ$ we denote $FV_ι(ψ)$ (resp.
  $FV_σ(ψ)$, resp. $FV_τ(ψ)$) the set of free $λ$-variables (resp. free
  $μ$-variables, resp. free term variables) of $ψ$. We also denote
  $FV(ψ) = FV_ι(ψ) ∪ FV_σ(ψ) ∪ FV_τ(ψ)$ the set of all the free variables
  of $ψ$. We say that $ψ$ is closed if $FV(ψ) = ∅$. We denote $Λ_{ι}^{*}$
  the set of all the closed values, $Λ^{*}$ the set of all the closed terms,
  and $Π^{*}$ the set of all the closed stacks.
\end{definition}

\begin{definition}[substitutions]
  A substitution is a map $ρ$ such that for all $x ∈ \mathcal{V}_{ι}$ we have
  $ρ(x) ∈ Λ_{ι}$, for all $α ∈ \mathcal{V}_{σ}$ we have $ρ(α)∈Π$, and for all
  $a ∈ \mathcal{V}_{τ}$ we have $ρ(a) ∈ Λ$. Importantly, we also require that
  $ρ(χ) ≠ χ$ for only finitely many $χ ∈ \mathcal{V}_ι ∪ \mathcal{V}_{σ} ∪
  \mathcal{V}_{τ}$. We denote $\mathcal{S}$ the set of all the substitutions,
  and $dom(ρ) = \{χ \st ρ(χ) ≠ χ\}$ the (finite) domain of the substitution
  $ρ$. In particular, $ρ_{id} ∈ \mathcal{S}$ is called the identity
  substitution and is defined as $ρ_{id}(χ) = χ$ for all
  $χ ∈ \mathcal{V}_{ι} ∪ \mathcal{V}_{σ} ∪ \mathcal{V}_{τ}$.
  %
  For every $ρ ∈ \mathcal{S}$ we denote $ρ[x := v]$ (resp. $ρ[α := π]$, resp.
  $ρ[a := t]$) the substitution remapping the variable $x ∈ \mathcal{V}_ι$
  (resp. $α ∈ \mathcal{V}_{σ}$, resp. $a ∈ \mathcal{V}_{τ}$) to the value
  $v ∈ Λ_{ι}$ (resp. stack $π ∈ Π$, resp. term $t ∈ Λ$) in $ρ$. In the case
  where $ρ = ρ_{id}$ we will simply write $[x := v]$, $[α := π]$ and
  $[a := t]$.
  %
  Let $ρ ∈ \mathcal{S}$ be a substitution and $ψ$ be a value, term, stack
  or process. We denote $ψρ$ the value, term, stack or process formed by
  simultaneously substituting (without capture) every variable $χ ∈ FV(ψ)$
  with $ρ(χ)$ in $ψ$.
\end{definition}
\begin{definition}[composition of substitutions]
  Given $ρ_1$, $ρ_2 ∈ \mathcal{S}$ we denote $ρ_1 ∘ ρ_2$ the substitution
  formed by composing $ρ_1$ and $ρ_2$. It is defined by taking
  $(ρ_1 ∘ ρ_2)(χ) = (ρ_1(χ))ρ_2$ for all $χ ∈ dom(ρ_1)$ and it coincides
  with $ρ_2$ on every other variables. In particular, if $ψ$ is a value,
  term, stack or process we will have $ψ(ρ_1 ∘ ρ_2) = (ψρ_1)ρ_2$.
\end{definition}

\begin{figure}
  \begin{align*}
    \hspace{4.5cm}%hack
    t\,u ∗ π          &\quad\;≻\quad  u ∗ [t\;\,{-}]π   \tag{Push}\\
    v ∗ [t\;\,{-}]π   &\quad\;≻\quad  \,t ∗ [{-}\;v]π  
                         \tag{if $v ∉ \mathcal{V}_{ι} ∪ \{\square\}$, Swap}\\
    λx.t ∗ [{-}\;v]π  &\quad\;≻\quad  t[x := v] ∗ π     \tag{Pop} \\
    μα.t ∗ π          &\quad\;≻\quad  t[α := π] ∗ π     \tag{Save}\\
    [ξ]t ∗ π          &\quad\;≻\quad  t ∗ ξ             \tag{Restore}\\
    \{(l_i = v_i)_{i∈I}\}.l_k ∗ π
                      &\quad\;≻\quad  v_k ∗ π       \tag{if $k ∈ I$, Find}\\
    [C_k[v]\,| (C_i[x_i] → t_i)_{i∈I}] ∗ π
                      &\quad\;≻\quad  t_k[x_k := v] ∗ π
                                                    \tag{if $k ∈ I$, Match}\\
    φa.v ∗ π          &\quad\;≻\quad  v[a := φa.v] ∗ π  \tag{Unfold}\\
    R(\{(l_i = v_i)_{i∈I}\},t) * π
                      &\quad\;≻\quad  t ∗ π             \tag{R-Rule}\\
    \square ∗ [t\;\,{-}]π
                      &\quad\;≻\quad  \square ∗ π       \tag{Erase 1}\\
    \square ∗ [{-}\;v]π
                      &\quad\;≻\quad  \square ∗ π       \tag{Erase 2}\\
    [\square\,| (C_i[x_i] → t_i)_{i∈I}]
                      &\quad\;≻\quad  \square ∗ π       \tag{Erase 3}\\
    \square.l_k ∗ π   &\quad\;≻\quad  \square ∗ π       \tag{Erase 4}
  \end{align*}
  \caption{Base reduction relation for the abstract machine.}
  \label{fig:base_red}
\end{figure}

Processes form the internal state of our abstract machine. They are to be
thought of as a term put in some evaluation context represented using a
stack. Intuitively, the stack $π$ in the process $t∗π$ contains the
arguments to be fed to $t$. Since we are in call-by-value the stack also
handles the storing of functions while their arguments are being evaluated.
The operational semantics of our language is given by a relation $(≻)$
over processes.
\begin{definition}[base reduction relation]
  The relation $(≻) ⊆ (Λ×Π) × (Λ×Π)$ is defined as the smallest relation
  satisfying the reduction rules of Figure~\ref{fig:base_red}. We denote
  $(≻^{+})$ its transitive closure, $(≻^{*})$ its reflexive-transitive
  closure and $(≻^k)$ its $k$-fold application.
\end{definition}

The rules (Push), (Swap) and (Pop) are those that handle $β$-reduction. When
the abstract machine encounters an application, the term that is in function
position is stored on the stack to evaluate its argument first. Once the
argument has been completely computed, a value faces the stack containing the
function. The function can then be evaluated with the computed (value)
argument stored on the stack, ready to be consumed by the function as soon as
it evaluates to a $λ$-abstraction. A capture-avoiding substitution can then be
performed to effectively apply the argument to the function.

The (Save) and (Restore) rules handle the classical part of computation. When
a $μ$-abstraction is reached, the current stack is captured and substituted
for the corresponding $μ$-variable. Conversely, when a term of the form $[ξ]t$
is reached, the current stack is discarded and evaluation resumes with the
process $t ∗ ξ$. The rules (Find), (Match) and (Unfold) are provided to handle
record projection, case analysis and recursion respectively.

A rule is then provided for reducing processes of the form $R(v,t) ∗ π$ to
$t ∗ π$ when the value $v$ is a record. Note that if $v$ is not a record then
no reduction rule apply on processes of the form $R(v,t) ∗ π$. These facts
will be used in to show that records, $λ$-abstractions and other forms of
values have a different computational behaviour in our abstract machine.
The last four rules are used to handle the special value $□$, which consumes
the surrounding part of its computational environment. This will be discussed
further when defining the semantical interpretation of our type system.
%
Finally, note that processes of the form $δ(v,w,t) ∗ π$ are left untouched
by the relation $(≻)$. They will however be given a reduction rule in the
following section.

\begin{theorem}[compatibility of reduction and substitution]\label{thm:redcompatall}%
  Let $ρ ∈ \mathcal{S}$ be a substitution and $p$, $q ∈ Λ×Π$ be two processes.
  If $p ≻ q$ (resp. $p ≻^{*} q$, resp. $p ≻^{+} q$, resp. $p ≻^k q$) then
  $pρ ≻ qρ$ (resp. $pρ ≻^{*} qρ$, resp $pρ ≻^{+} qρ$, resp. $pρ ≻^k qρ$).
\end{theorem}
\begin{proof}
  Immediate case analysis (and induction), all rules being local.
\end{proof}

\section{Classification of processes}

We are now going to give the vocabulary that will be used to describe specific
classes of processes. In particular we need to identify processes that are to
be considered as the evidence of a successful computation, and those that are
to be recognised as the expression of a failure (e.g., a crash).
\begin{definition}[classification of processes]
  A process $p ∈ Λ×Π$ is said to be:
  \begin{itemize}
    \item \emph{final} if $p = v∗ε$ for some $v ∈ Λ_{ι}$,
    \item \emph{$δ$-like} if $p = δ(v,w,t) ∗ π$ for some $v,w ∈ Λ_{ι}$,
      $t ∈ Λ$ and $π ∈ Π$,
    \item \emph{blocked} if there is no $q ∈ Λ×Π$ such that $p ≻ q$,
    \item \emph{stuck} if it is not final nor $δ$-like and if $pρ$ is
      blocked for all $ρ ∈ \mathcal{S}$,
    \item \emph{non-terminating} if there is an infinite sequence
      $(p_i)_{i∈\mathbb{N}}$ with $p_0 = p$ and $p_i ≻ p_{i+1}$.
  \end{itemize}
\end{definition}

When a process becomes stuck, non-terminating or $δ$-like during its
reduction, it will remain so forever. In particular, no substitution
will ever be able to turn it into a process that might lead to a
successful end of computation (i.e., reduce to a final process).
\begin{lemma}[stability under substitution]\label{lem:redstable}%
  Let $p ∈ Λ×Π$ be a process and $ρ ∈ \mathcal{S}$ be a substitution. If $p$
  is final (resp. $δ$-like, stuck, non-terminating), then so is $pρ$.
\end{lemma}
\begin{proof}
  If $p$ is final then $p = v∗ε$ for some $v ∈ Λ_{ι}$. Since $(v∗ε)ρ =
  vρ∗ερ = vρ∗ε$ the process $pρ$ is also final. If $p$ is $δ$-like then
  $p = δ(v,w,t)∗π$ for some $v$, $w ∈ Λ_{ι}$, $t ∈ Λ$ and $π ∈ Π$. Since
  $(δ(v,w,t)∗π)ρ = (δ(v,w,t))ρ ∗ πρ = δ(vρ,wρ,tρ) ∗ πρ$ the process $pρ$
  is also $δ$-like. If $p$ is stuck, then we suppose that there is a
  substitution $ρ_0 ∈ \mathcal{S}$ such that $(pρ)ρ_0$ is not blocked.
  This contradicts the fact that $p$ is stuck since $p(ρ_0 ∘ ρ) = (pρ)ρ_0$
  is not blocked, and hence $pρ$ must be stuck. Finally, if $p$ is
  non-terminating then we have a sequence $(p_i)_{i∈\mathbb{N}}$ such that
  $p_0 = p$ and $p_i ≻ p_{i+1}$ for all $i ∈ \mathbb{N}$. To show that
  $pρ$ is non-terminating we need to construct a sequence
  $(q_i)_{i∈\mathbb{N}}$ such that $q_0 = pρ$ and $q_i ≻ q_{i+1}$ for
  all $i ∈ \mathbb{N}$. We can take $q_i = p_iρ$ for all $i ∈ \mathbb{N}$.
  Indeed, we have $q_0 = pρ$ since $p₀ = p$ and for all $i ∈ \mathbb{N}$ we
  have $p_iρ ≻ p_{i+1}ρ$ by Lemma~\ref{thm:redcompatall} as $p_i ≻ p_{i+1}$.
\end{proof}

\begin{lemma}[characterization of stuck processes]\label{remark}%
  A process is stuck if and only if it is of one of the following forms,
  where $n$, $m$, $k ∈ \mathbb{N}$ and $I$, $J$, $K ⊆_{fin} \mathbb{N}$ such
  that $k ∉ K$.
  \begin{center}
  $
    \hspace{1.5cm}
    C_n[v].l_m ∗ π
    \hfill
    (λx.t).l_m ∗ π
    \hfill
    C_n[v] ∗ [{-}\;w]π
    \hfill
    \{(l_i = v_i)_{i∈I}\} ∗ [{-}\;v]π
    \hspace{1.5cm}
  $
  \\[2mm]
  $
    \hspace{1.5cm}
    [λx.t\,| (C_i[x_i] → t_i)_{i∈I}] ∗ π
    \hfill
    [\{(l_i = v_i)_{i∈I}\}\,| (C_j[x_j] → t_j)_{j∈J}] ∗ π
    \hspace{1.5cm}
  $
  \\[2mm]
  $
    \hspace{1.5cm}
    [C_k[v]\,|(C_i[x_i] → t_i)_{i∈K}] ∗ π
    \hfill
    \{(l_i = v_i)_{i∈K}\}.l_k ∗ π
    \hspace{1.5cm}
  $
  \\[2mm]
  $
    \hspace{1.5cm}
    R(λx.t,u) ∗ π
    \hfill
    R(C_n[v],u) ∗ π
    \hfill
    R(□,u) ∗ π
    \hspace{1.5cm}
  $
  \end{center}
  \vspace{-3mm}%hack
\end{lemma}
\begin{proof}
  Using a simple case analysis we first rule out the thirteen forms of
  processes that immediately reduce using $(≻)$. As stuck processes are
  neither final nor $δ$-like, we can again rule out two forms of processes.
  We are now left with eighteen forms of processes, among which seven
  are not stuck (see the proof of Lemma~\ref{lem:possibilities}). It is easy
  to see that the eleven remaining forms of processes are stuck. Indeed, given
  their structure no reduction rule will ever apply to them, even after a
  substitution.
\end{proof}
The proof of Lemma~\ref{remark} has been (partially) checked using OCaml's
exhaustivity checker for patterns. Indeed, the abstract syntax tree
corresponding to our language can be encoded into OCaml data types easily.
It is then possible to use pattern matching to enumerate possible forms of
processes in such a way that it is neither redundant nor incomplete (i.e.,
that the OCaml compiler does not complain with a warning). The OCaml source
file used for this purpose is available online.
\begin{center}
  \url{https://lepigre.fr/these/classification.ml}
\end{center}

\begin{lemma}[characterization of blocked processes]\label{lem:possibilities}%
  A blocked process $p ∈ Λ×Π$ is either stuck, final, $δ$-like, or of one of
  the following seven forms.
  \begin{center}
  $
    \hspace{1.5cm}
    x.l_k ∗ π
    \hfill
    x ∗ [{-}\;v]π
    \hfill
    [x\,| (C_i[x_i] → t_i)_{i∈I}] ∗ π
    \hspace{1.5cm}
  $
  \\[2mm]
  $
    \hspace{1.5cm}
    x ∗ [t\;\,{-}]π
    \hfill
    R(x,u) ∗ π
    \hfill
    a ∗ π
    \hfill
    v ∗ α
    \hspace{1.5cm}
  $
  \end{center}
\end{lemma}
\begin{proof}
  As for Lemma~\ref{remark}, we can rule out the thirteen forms of
  processes that immediately reduce using $(≻)$, final processes and
  $δ$-like processes. After ruling out the eleven forms of stuck processes
  of Lemma~\ref{remark} we are left with seven forms of processes. It
  remains to show that they are not stuck by finding a substitution
  $ρ ∈ \mathcal{S}$ unlocking their reduction.

  For processes of the first four forms we can take $ρ = [x := □]$
  since we have $□.l_k ∗ πρ ≻ □ ∗ πρ$, $□ ∗ [{-}\;vρ]πρ ≻ □ ∗ πρ$,
  $[□\,| (C_i[x_i] → t_iρ)_{i∈I}] ∗ π ≻ □ ∗ πρ$ and
  $□ ∗ [tρ\;\,{-}]πρ ≻ □ ∗ πρ$ respectively.
  %
  For a process of the form $R(x,u) ∗ π$ we can take $ρ = [x := \{\}]$ as
  $R(\{\},uρ) ∗ πρ ≻ uρ ∗ πρ$.
  %
  For a process of the form $a ∗ π$ we can take $ρ=[a := \{l_k=\{\}\}.l_k]$
  as $\{l_k = \{\}\}.l_k ∗ πρ ≻ \{\} ∗ πρ$.
  %
  Finally, for a process of the form $v ∗ α$ we can take
  $ρ = [α := [\{\}\;{-}]ε]$ as we will have
  $vρ ∗ [\{\}\;{-}]ε ≻ \{\} ∗ [{-}\;vρ]ε$ if $v ≠ □$ and
  $vρ ∗ [\{\}\;{-}]ε ≻ □ ∗ ε$ otherwise.
\end{proof}

\section{Stratified equivalence and reduction relations}

Let us first consider generic definitions related to reduction relations. In
particular, we will give a generic way to derive the observational equivalence
relation induced by a reduction relation.
\begin{definition}[convergence/divergence]
  Let $R ⊆ (Λ×Π) × (Λ×Π)$ be a reduction relation such that for every final
  process $p ∈ Λ×Π$, there is no $q ∈ Λ×Π$ such that $p \mathrel{R} q$. We
  say that a process $p ∈ Λ×Π$ converges for the relation $R$,
  and we write $p {⇓}_R$, if there is a final process $q ∈ Λ×Π$
  such that $p \mathrel{R^{∗}} q$. If $p$ does not converge we say that it
  diverges (for the relation $R$) and we write $p {⇑}_R$.
\end{definition}
\begin{definition}[observational equivalence]
  Let $R ⊆ (Λ×Π) × (Λ×Π)$ be a reduction relation. The observational
  equivalence relation induced by $R$ is denoted $(≡_R)$ and defined as
  follows.
  \begin{center}
  $
    (≡_R) = \{(t,u) \st ∀π∈Π, ∀ρ∈\mathcal{S}, tρ∗π {⇓}_R ⇔ uρ∗π {⇓}_R\}
  $
  \end{center}
  \vspace{-3mm}%hack
\end{definition}
\begin{lemma}\label{obseqRequiv}%
  For all $R ⊆ (Λ×Π) × (Λ×Π)$, $(≡_R)$ is an equivalence relation.
\end{lemma}
\begin{proof}
  Immediate by definition.
\end{proof}

The idea now is to extend our reduction relation $(≻)$ with a new,
surprising reduction rule. It will reduce processes of the form
$δ(v,w,t)∗π$ to $t∗π$ in the case where $v \not\equiv w$ for some
equivalence relation $(≡)$, and remain stuck otherwise. However, by
adding such a reduction rule, it is not possible to take $(≡) = (≡_{≻})$.
Indeed, this would make the definitions of reduction and equivalence
circular. Consequently, we need to be very careful so that everything
remains well-defined. We will rely on a stratified construction of both
the reduction relation and the equivalence relation.
\begin{definition}[stratification]
  For all $i ∈ \mathbb{N}$ we define two relations $(↠_i)$ and $(≡_i)$ as
  follows.
  \begin{center}
  $
    \hspace{1.5cm}
    (↠_i) = (≻) ∪ \{(δ(v,w,t)∗π, t∗π) \st ∃j<i, v \not\equiv_j w\}
    \hfill
    (≡_i) = \cap_{j ≤ i} (≡_{↠_j})
    %\{(t,u) \st ∀j≤i, ∀π∈Π, ∀ρ∈\mathcal{S}, tρ∗π {⇓}_j ⇔ uρ∗π {⇓}_j\}
    \hspace{1.5cm}
  $
  \end{center}
  The relations are well-defined: although $(≡_i)$ depends on $(↠_j)$ for all
  $j ≤ i$, $(↠_i)$ only depends on $(≡_j)$ for all $j < i$. Note that
  $(↠_0) = ({≻})$ as there is no $j<0$, and hence $(≡_0) = (≡_{≻})$.
\end{definition}

\begin{lemma}\label{isequiv}%
  For all $i ∈ \mathbb{N}$, $(≡_i)$ is an equivalence relation.
\end{lemma}
\begin{proof}
  Immediate by Lemma~\ref{obseqRequiv}, an intersection of
  equivalence relations being one itself.
\end{proof}

We can then define our actual reduction relation and equivalence relation
as a union and an intersection over the previously defined relations.
\begin{definition}[reduction and equivalence]
  The relations $(↠)$ and $(≡)$ are defined as follows.
  \begin{center}
  $
    \hfill
    (↠) = \cup_{i∈\mathbb{N}} (↠_i)
    \hfill
    (≡) = \cap_{i∈\mathbb{N}} (≡_i)
    \hfill
  $
  \end{center}
  For convenience, we will generally use the following, equivalent
  formulations.

  \vspace{2mm}
  \noindent$\hspace{1.5cm} (≡) = \cap_{i∈\mathbb{N}} (≡_{↠_i})
    = \{(t,u) \st ∀i∈\mathbb{N}, ∀π∈Π,
    ∀ρ∈\mathcal{S}, tρ∗π {⇓}_i ⇔ uρ∗π {⇓}_i\}$

  \vspace{2mm}
  \noindent$\hspace{1.5cm} (\not\equiv) = \cup_{i∈\mathbb{N}} (\not\equiv_{↠_i})
    = \{(t,u), (u,t) \st ∃i∈\mathbb{N}, ∃π∈Π, ∃ρ∈\mathcal{S},
    tρ∗π {⇓}_i ∧ uρ∗π {⇑}_i\}$
  
  \vspace{2mm}
  \noindent$\hspace{1.5cm} (↠) = (≻) ∪ \{(δ(v,w,t)∗π, t∗π) \st v \not\equiv w\} $
\end{definition}
Note that the definition of $(↠)$ corresponds exactly to what we aimed
for: an extension of $(≻)$ with a reduction rule for $δ$-like terms
carrying two non-equivalent values.

\begin{remark}
  We have $(↠_i) ⊆ (↠_{i+1})$ and $(≡_{i+1}) ⊆ (≡_i)$. Consequently, the
  construction of $(↠_i)_{i∈\mathbb{N}}$ and $(≡_i)_{i∈\mathbb{N}}$ forms
  a fixpoint at the ordinal $ω$. Surprisingly, this property will not be
  explicitly required in the following.
\end{remark}
\begin{lemma}
  $(≡)$ is an equivalence relation.
\end{lemma}
\begin{proof}
  Immediate by Lemma~\ref{isequiv}, an intersection of equivalence relations
  being one itself.
\end{proof}

\section{Congruence properties for equivalence}

We are now going to establish important properties of our equivalence
relation $(≡)$. In particular, we will show that it behaves in the expected
way with respect to substitution. For instance, we will show that arbitrary
substitutions preserve equivalence, and that the substitution of equivalent
values in a term yields equivalent terms.

\begin{theorem}[substitutivity]\label{fullsubstequiv}%
  Let $t$, $u ∈ Λ$ be two terms and $ρ ∈ \mathcal{S}$ be a substitution. If
  $t ≡ u$ then $tρ ≡ uρ$.
\end{theorem}
\begin{proof}
  Let us take $i_0 ∈ \mathbb{N}$, $ρ_0 ∈ \mathcal{S}$ and $π_0 ∈ Π$, and prove
  ${{(tρ)ρ_0 ∗ π_0} {⇓}_{i_0}} ⇔ {{(uρ)ρ_0 ∗ π_0} {⇓}_{i_0}}$, which rewrites
  as ${{t(ρ_0 ∘ ρ) ∗ π_0} {⇓}_{i_0}} ⇔ {{u(ρ_0 ∘ ρ) ∗ π_0} {⇓}_{i_0}}$. We can
  thus conclude by definition of $t ≡ u$ using $i_0$, the substitution
  $ρ_0 ∘ ρ$ and the stack $π_0$.
\end{proof}

\begin{theorem}[extensionality for values]\label{fullextval}%
  Let $v_1$, $v_1 ∈ Λ_ι$ be values, $t ∈ Λ$ be a term and $x ∈ \cal{V}_ι$
  be a $λ$-variable. If we have $v_1 ≡ v_2$ then we also have
  ${t[x := v_1]} ≡ {t[x := v_2]}$.
\end{theorem}
\begin{proof}
  We are going to prove the contrapositive so we suppose ${t[x := v_1]}
  \not\equiv {t[x := v_2]}$ and we show $v_1 \not\equiv v_2$. Let us first
  assume that neither $v_1$ nor $v_2$ is equal to $□$ or to a $λ$-variables.
  By definition, we know that there $i∈\mathbb{N}$, $π∈Π$ and $ρ∈\mathcal{S}$
  such that ${(t[x := v_1])ρ ∗ π} {⇓}_i$ and ${(t[x := v_2])ρ ∗ π} {⇑}_i$ (up
  to symmetry). As $x$ is bound we can rename it in such a way that
  ${(t[x := v_1])ρ} = {tρ[x := v_1ρ]}$ and that ${(t[x := v_2])ρ} =
  {tρ[x := v_2ρ]}$. To finish the proof, we need to find $i_0 ∈ \mathbb{N}$,
  $π_0 ∈ Π$ and $ρ_0 ∈ \mathcal{S}$ such that ${v_1ρ_0 ∗ π_0} {⇓}_{i_0}$
  and ${v_2ρ_0 ∗ π_0} {⇑}_{i_0}$ (up to symmetry). We can take $i_0 = i$,
  $π_0 = {[(λx.tρ)\;\,{-}]π}$ and $ρ_0 = ρ$ since ${v_1ρ ∗ [(λx.tρ)\;\,{-}]π}
  ↠_i {tρ[x := v_1ρ] ∗ π} {⇓}_i$ and ${v_2ρ ∗ [(λx.tρ)\;\,{-}]π} ↠_i
  {tρ[x := v_2ρ] ∗ π} {⇑}_i$. Note that here, it is essential that $v_1ρ$ and
  $v_2ρ$ are not equal to $□$ or to some $λ$-variable, as otherwise the first
  reduction steps could not be taken.

  It remains to show that $v_1 \not\equiv v_2$ when either $v_1$ or $v_2$
  (or both) is equal to $□$ or to a $λ$-variable. First, we can assume
  $v_1 ≠ v_2$ as otherwise we would immediately get a contradiction with
  ${t[x := v_1]} \not\equiv {t[x := v_2]}$ by reflexivity of $({≡})$. As a
  consequence, it is not possible that $v_1 = v_2 = □$ or that $v_1 = v_2 =
  x ∈ \mathcal{V}_{ι}$.
  %
  Let us consider the case where $v_1 = x ∈ \mathcal{V}_{ι}$ and $v_2 = □$,
  or symmetrically, $v_1 = □$ and $v_2 = x ∈ \mathcal{V}_{ι}$. To tell these
  values apart we can show $v_1 \not\equiv_0 v_2$ using the substitution
  $ρ = [x := \{\}]$ and the stack $π = [{-}\;\,\{\}]ε$. Indeed, we have
  ${□ρ ∗ π} = {□ ∗ [{-}\;\,\{\}]ε} ↠_0 {□ ∗ ε}  {⇓}_0$ and ${xρ ∗ π} =
  {\{\} ∗ [{-}\;\,\{\}]ε} {⇑}_0$.
  %
  The only remaining case is the one where $v_1 = x ∈ \mathcal{V}_{ι}$ and
  $v_2 = y ∈ \mathcal{V}_{ι}$, with $x ≠ y$. To tell these values apart we
  show $v_1 \not\equiv_0 v_2$ using the substitution $ρ = [x := \{\}][y := □]$
  and (again) the stack $π = [{-}\;\,\{\}]ε$. Indeed, ${v_1ρ ∗ π} =
  {\{\} ∗ [{-}\;\,\{\}]ε} {⇑}_0$ and
  ${v_2ρ ∗ π} = {□ ∗ [{-}\;\,\{\}]ε} {⇓}_0$.
\end{proof}

A result analogous to Theorem~\ref{fullextval} also holds for substituting
equivalent terms to a term variable. However, it is harder to prove, and it
requires a proof by induction on the reduction levels. The core of the proof
happens in that of Lemma~\ref{afullextlem}, which itself makes use of the
following lemma.
\begin{lemma}\label{lem:aposs}%
  Let $p ∈ Λ×Π$ be a process, $t ∈ Λ$ be a term, and $a ∈ \mathcal{V}_τ$ be a
  term variable. If ${p[a := t]} {⇓}_k$ for some $k ∈ \mathbb{N}$ then there
  is a blocked process $q ∈ Λ×Π$ such that $p ≻^{∗} q$ and either:
  \begin{itemize}
    \item $q = {v ∗ ε}$ for some value $v ∈ Λ_{ι}$,
    \item $q = {a ∗ π}$ for some stack $π ∈ Π$,
    \item $k ≠ 0$ and $q = {δ(v,w,u) ∗ π}$ for some values $v$, $w ∈ Λ_{ι}$,
      term $t ∈ Λ$ and stack $π ∈ Π$. Moreover, in this case, we also know
      that ${v[a := t]} \not\equiv_j {w[a := t]}$ for some $j < k$.
  \end{itemize}
\end{lemma}
\begin{proof}
  If $p$ is non-terminating then so is $p[a := t]$ according to
  Lemma~\ref{lem:redstable}. Since $({≻}) ⊆ ({↠}_k)$ this contradicts
  ${{p[a := t]}} {⇓}_k$, and thus there must be a blocked process $q ∈ Λ×Π$
  such that $p ≻^{∗} q$. Using Theorem~\ref{thm:redcompatall} we obtain
  ${p[a := t]} ≻^{∗} {q[a := t]}$, which tells us that ${q[a := t]} {⇓}_k$.
  This means that $q$ cannot be stuck, as otherwise $q[a := t]$ would also be
  stuck by Lemma~\ref{lem:redstable}, and that would contradict
  ${q[a := t]} {⇓}_k$.
  %
  Let us now suppose that $p = {δ(v,w,u) ∗ π}$ for some $v$, $w ∈ Λ_ι$,
  $t ∈ Λ$, and $π ∈ Π$. Since ${δ(vρ,wρ,uρ) ∗ π} {⇓}_k$, there must be $j < k$
  (and thus $k ≠ 0$) such that ${vρ} \not\equiv_j {wρ}$, otherwise we would
  obtain a contradiction.
  %
  By Lemma~\ref{lem:possibilities}, it remains to rule out the following forms
  for $q$, where $b ≠ a$.
  \begin{center}
  $
    \hspace{1.5cm}
    x.l_k ∗ π
    \hfill
    x ∗ [{-}\;v]π
    \hfill
    [x\,| (C_i[x_i] → t_i)_{i∈I}] ∗ π
    \hspace{1.5cm}
  $
  \\[2mm]
  $
    \hspace{1.5cm}
    x ∗ [t\;\,{-}]π
    \hfill
    R(x,u) ∗ π
    \hfill
    b ∗ π
    \hfill
    v ∗ α
    \hspace{1.5cm}
  $
  \end{center}
  It is however easy to see that if $q$ was of one of these forms, then
  $q[a := t]$ would still be blocked, and that would again contradict
  ${q[a := t]} {⇓}_k$.
\end{proof}
\begin{lemma}\label{afullextlem}%
  Let $u_1$, $u_2$, $t ∈ Λ$ be three terms, $a ∈ \mathcal{V}_τ$ be a term
  variable, and $k ∈ \mathbb{N}$ be a natural number. If $u_1 ≡_k u_2$ then
  ${t[a := u_1]} ≡_k {t[a := u_2]}$.
\end{lemma}
\begin{proof}
  We do a proof by induction on the equivalence level, so we take $k_0 ∈
  \mathbb{N}$ and we assume that the property holds for all $k < k_0$. We
  then suppose that $u_1 ≡_{k_0} u_2$ and show ${t[a := u_1]} ≡_{k_0}
  {t[a := u_2]}$. By definition, we need to take $π ∈ Π$, $ρ ∈ \mathcal{S}$
  and show ${{(t[a := u_1])ρ∗π} {⇓}_{k_0}} ⇔ {{(t[a := u_2])ρ∗π} {⇓}_{k_0}}$.
  Since $a$ is bound we are free to rename it, hence we may assume
  ${(t[a := u_1])ρ} = {tρ[a := u_1ρ]}$, ${(t[a := u_2])ρ} = {tρ[a := u_2ρ]}$
  and $a ∉ FV_τ(π) ∪ FV_τ(t_1) ∪ FV_τ(t_2)$. By symmetry, we can thus
  suppose ${tρ[a := u_1ρ] ∗ π} {⇓}_{k_0}$ and show
  ${tρ[a := u_2ρ] ∗ π} {⇓}_{k_0}$.

  We will now build a sequence $(t_i,π_i,l_i)_{i ∈ I}$ defined in such
  a way that for every natural number $i ∈ I$ we have ${tρ[a := u_1ρ] ∗ π}
  ↠_{k_0}^{∗} {t_i[a := u_1ρ] ∗ π_i[a := u_1ρ]}$ in $l_i$ steps, and
  $t_i ∗ p_i$ is blocked. We also require $(l_i)_{i ∈ I}$ to be increasing,
  and to have a strictly increasing subsequence. Under this condition the
  sequence must be finite, as if it was infinite then $tρ[a := u_1ρ]∗π$
  would be non-terminating, and this would contradict ${tρ[a := u_1ρ]∗π}
  {⇓}_{k_0}$. As a consequence, our sequence has a finite number $n+1$ of
  elements (for some $n ∈ \mathbb{N}$), and we can denote it
  $(t_i,π_i,l_i)_{i ≤ n}$. To show that $(l_i)_{i ≤ n}$ has a strictly
  increasing subsequence, we will ensure that it does not have three equal
  consecutive values.

  To define $(t_0,π_0,l_0)$ we look at the reduction of $tρ ∗ π$. As
  ${(tρ∗π)[a := u_1ρ]} = {tρ[a := u_1]∗π} {⇓}_{k_0}$, we can apply
  Lemma~\ref{lem:aposs} to obtain a blocked process $p$ such that
  ${tρ ∗ π} ≻^j p$. We then take ${t_0 ∗ π_0} = p$ and $l_0 = j$.
  According to Theorem~\ref{thm:redcompatall} we have
  ${(tρ ∗ π)[a := u_1ρ]} ≻^j {t_0[a := u_1ρ] ∗ π_0[a := u_1ρ]}$. As a
  consequence, we know that ${(tρ ∗ π)[a := u_1ρ]} ↠_{k_0}^{∗}
  {t_0[a := u_1ρ] ∗ π_0[a := u_1ρ]}$ in $l_0 = j$ steps.
  %
  To define $(t_{i+1},π_{i+1},l_{i+1})$, we consider the (already constructed)
  blocked  process ${t_i ∗ π_i}$. By construction, we know that
  ${tρ[a := u_1ρ] ∗ π} ↠_{k_0}^{∗} {t_i[a := u_1ρ] ∗ π_i[a := u_1ρ]}$ in $l_i$
  steps. Hence, by Lemma~\ref{lem:aposs}, we know that $t_i ∗ π_i$ can only be
  of three different shapes.
  \begin{itemize}
    \item If ${t_i ∗ π_i} = {v ∗ ε}$ for some $v ∈ Λ_ι$ then the sequence ends
      with $n = i$.
    \item If $t_i = a$ then we consider the process ${t_i[a := u_1ρ] ∗ π_i}$.
      By construction, we know that we have
      ${(t_i[a := u_1ρ] ∗ π_i)[a := u_1ρ]} {⇓}_{k_0}$,
      and Lemma~\ref{lem:aposs} gives us a blocked process $p$ such that
      ${t_i[a := u_1ρ] ∗ π_i} ≻^j p$. By Theorem~\ref{thm:redcompatall}
      ${(t_i[a := u_1ρ] ∗ π_i)[a := u_1ρ]} ≻^j {p[a := u_1ρ]}$, and hence
      ${t_i[a := u_1ρ] ∗ π_i[a := u_1ρ]} ↠_{k_0}^{∗} {p[a := u_1ρ]}$ in $j$
      steps. We then take as definition ${t_{i+1} ∗ π_{i+1}} = p$ and
      $l_{i+1} = l_i + j$.
      %
      Now, is it possible to have $j = 0$? This can only happen when
      ${t_i[a := u_1ρ] ∗ π_i}$ is of one of the three forms of
      Lemma~\ref{lem:aposs}. It cannot be of the form ${a ∗ π}$ as we assumed
      that $a$ does not appear in $u_1ρ$. If it is of the form $v ∗ ε$, then
      we reached the end of the sequence with $i = n$ so there is no problem.
      We only have to be careful when ${t_i[a := u_1ρ]} = {δ(v,w,u)}$. In
      this case, we will make sure that we always have $l_{i+2} > l_{i+1}$
      (see the following case).
    \item If $t_i = {δ(v,w,u)}$ for some $v$, $w ∈ Λ_ι$ and $u ∈ Λ$, then we
      know ${v[a := u_1ρ]} \not\equiv_m {w[a := u_1ρ]}$ for some $m < k_0$
      (here $k_0 ≠ 0$, so this case is trivial in the base case of our
      induction). Hence, we have ${t_i[a := u_1ρ] ∗ π_i} = {δ(v[a := u_1ρ],
      w[a := u_1ρ], u[a := u_1ρ]) ∗ π_i} ↠_{k_0} {u[a := u_1ρ] ∗ π_i}$.
      Moreover, ${t_i[a := u_1ρ] ∗ π_i[a := u_1ρ]} ↠_{k_0}
      {u[a := u_1ρ] ∗ π_i[a := u_1ρ]}$ by definition of $({↠}_{k_0})$. Since
      we know that ${t[a := u_1ρ] ∗ π} ↠_{k_0}^{∗} {t_i[a := u_1ρ] ∗ π_i[a :=
      u_1ρ]}$ in $l_i$ steps, we get that ${t[a := u_1ρ] ∗ π} ↠_{k_0}^{∗}
      {u[a := u_1ρ] ∗ π_i[a := u_1ρ]}$ in $l_i+1$ steps. And moreover, we also
      know that ${(u[a := u_1ρ] ∗ π_i)[a := u_1ρ]} = {u[a := u_1ρ] ∗ π_i[a :=
      u_1ρ]} {⇓}_{k_0}$.
      %
      We now consider the reduction of the process ${u[a := u_1ρ]∗π_i}$.
      According to Lemma~\ref{lem:aposs} there is a blocked process $p$ such
      that ${u[a := u_1ρ]∗π_i} ≻^j p$. Using Theorem~\ref{thm:redcompatall} we
      obtain ${u[a := u_1ρ] ∗ π_i[a := u_1ρ]} ≻^j {p[a := u_1ρ]}$ from which
      we deduce that ${u[a := u_1ρ] ∗ π_i[a := u_1ρ]} ↠_{k_0}^{∗} {p[a :=
      u_1ρ]}$ in $j$ steps. We then define ${t_{i+1} ∗ π_{i+1}} = p$ and
      $l_{i+1} = l_i + j + 1$. Note the that we indeed have $l_{i+1} > l_i$.
  \end{itemize}
  Intuitively, the sequence $(t_i,π_i,l_i)_{i ≤ n}$ mimics the reduction of
  the process $t[a := u_1ρ] ∗ π$, while making explicit every substitution of
  $a$ and every reduction of a $δ$-like state.

  To end the proof, we will show that for all $i ≤ n$ we have
  ${t_i[a := u_2ρ] ∗ π_i[a := u_2ρ]} {⇓}_{k_0}$. For $i = 0$, this will give
  us ${t[a := u_2ρ]∗π} {⇓}_{k_0}$, which is the expected result. As by
  construction ${t_n ∗ π_n} = {v ∗ ε}$, we have ${t_n[a := u_2ρ] ∗ π_n[a :=
  u_2ρ]} = {v[a := u_2ρ]∗ε}$, and hence ${t_n[a := u_2ρ] ∗ π_n[a := u_2ρ]}
  {⇓}_{k_0}$.
  %
  We now assume ${t_{i+1}[a := u_2ρ] ∗ π_{i+1}[a := u_2ρ]} {⇓}_{k_0}$ for
  $0 ≤ i < n$, and show ${t_i[a := u_1ρ] ∗ π_i[a := u_2ρ]} {⇓}_{k_0}$.
  By construction, $t_i ∗ π_i$ can be of two shapes, since only $t_n ∗ π_n$
  can be of the form $v ∗ ε$.
  \begin{itemize}
    \item If $t_i = a$ then we know that ${u_1ρ ∗ π_i} ↠_{k_0}^{∗}
      {t_{i+1} ∗ π_{i+1}}$. As a consequence, Theorem~\ref{thm:redcompatall}
      gives us ${u_1ρ ∗ π_i[a := u_2ρ]} ↠_{k_0}^{∗} {t_{i+1}[a := u_2ρ] ∗
      π_i[a := u_2ρ]}$, and we then get ${u_1ρ ∗ π_i[a := u_2ρ]} {⇓}_{k_0}$
      by induction hypothesis. Since $u_1 ≡_{k_0} u_2$, this implies
      ${u_2ρ ∗ π_i[a := u_2ρ]} = {(t_i ∗ π_i)[a := u_2ρ]} {⇓}_{k_0}$.

    \item If $t_i = δ(v,w,u)$ then we have ${u ∗ π_i} ↠_{k_0}^{∗} {t_{i+1} ∗
      π_{i+1}}$. As a consequence, Theorem~\ref{thm:redcompatall} gives us
      ${u[a := u_2ρ] ∗ π_i[a := u_2ρ]} ↠_{k_0}^{∗} {t_{i+1}[a := u_2ρ] ∗
      π_{i+1}[a := u_2ρ]}$. Using the induction hypothesis we obtain
      ${u[a := u_2ρ] ∗ π_i[a := u_2ρ]} {⇓}_{k_0}$. To conclude the proof, it
      remains to show that ${δ(v[a := u_2ρ],w[a := u_2ρ], u[a := u_2ρ]) ∗
      π_i[a := u_2ρ]} ↠_{k_0}^{∗} {u[a := u_2ρ] ∗ π_i[a := u_2ρ]}$.
      %
      We need to find $j < k_0$ such that ${v[a := u_2ρ]} \not\equiv_j
      {w[a := u_2ρ]}$. By construction, there is $m < k_0$ such that
      ${v[a := u_1ρ]} \not\equiv_m {w[a := u_1ρ]}$, and we will show
      ${v[a := u_2ρ]} \not\equiv_m {w[a := u_2ρ]}$. Using the global
      induction hypothesis twice, we obtain that ${v[a := u_1ρ]} ≡_m
      {v[a := u_2ρ]}$ and that ${w[a := u_1ρ]} ≡_m {w[a := u_2ρ]}$.
      Now if we suppose ${v[a := u_2ρ]} ≡_m {w[a := u_2ρ]}$ then we
      have ${v[a := u_1ρ]} ≡_m {v[a := u_2ρ]} ≡_m {w[a := u_2ρ]} ≡_m
      {w[a := u_1ρ]}$. As this contradicts the fact that
      ${v[a := u_1ρ]} \not\equiv_m {w[a := u_1ρ]}$, it must be that
      ${v[a := u_2ρ]} \not\equiv_m {w[a := u_2ρ]}$.
  \end{itemize}
\end{proof}
\begin{theorem}[extensionality for terms]\label{fullextterm}%
  Let $u_1$, $u_2$, $t ∈ Λ$ be three terms and $a ∈ \mathcal{V}_{τ}$ be a term
  variable. If we have $u_1 ≡ u_2$ then we also have
  ${t[a := u_1]} ≡ {t[a := u_2]}$.
\end{theorem}
\begin{proof}
  We suppose that $u_1 ≡ u_2$, which means that $u_1 ≡_i u_2$ for all
  $i ∈ \mathbb{N}$. We need to show that ${t[a := u_1]} ≡ {t[a := u_2]}$
  so we take $i_0 ∈ \mathbb{N}$ and we show ${t[a := u_1]} ≡_{i_0}
  {t[a := u_2]}$. By hypothesis we have $u_1 ≡_{i_0} u_2$ and hence we can
  conclude using Lemma~\ref{afullextlem}.
\end{proof}

\section{Partial axiomatization of equivalence}

The equivalence relation $(≡)$ plays an important rôle in the interpretation
of the types of the language. As a consequence, we will very often need to
perform equational reasoning, but the definition of the relation cannot be
directly implemented as a decision procedure. To solve this problem, we will
now extract a partial axiomatization of $(≡)$ from its definition. This
formulation will then allow us to easily implement a partial decision
procedure. A summary of the results of this section is displayed in
Figure~\ref{fig:axiomatization_equiv}.

\begin{figure}
  \centering
  Reduction steps as equivalences
  %
  \begin{align*}
    % CBV β-reduction
    (λx.t)\;v &\;≡\; t[x := v]
    \tag{if $x ∈ \mathcal{F}_{ι}$, $t ∈ Λ$, and $v ∈ Λ_{ι} \setminus
    (\mathcal{V}_{ι} ∪ \{□\})$}\\
    % Application with box
    t\;□ &\;≡\; v\;□ \;≡\;□
    \tag{if $t ∈ Λ$, resp. $v ∈ Λ_{ι} \setminus (\mathcal{V}_{ι} ∪ \{□\})$}\\
    % Record projection
    \{(l_i = v_i)_{i∈I}\}.l_k &\;≡\; v_k
    \tag{if $k ∈ I ⊆_\text{fin} \mathbb{N}$ and $∀i∈I, v_i ∈ Λ_{ι}$}\\
    % Box projection
    □.l_k &\;≡\; □
    \tag{if $k ∈ \mathbb{N}$}\\
    % Pattern-matching
    [C_k[v]\,| (C_i[x_i] → t_i)_{i∈I}] &\;≡\; t_k[x_k := v]
    \tag{if $k ∈ I ⊆_\text{fin} \mathbb{N}$, $v ∈ Λ_{ι}$,
    and $∀i∈I, (x_i, t_i) ∈ \mathcal{V}_{ι} × Λ$}\\
    % Box matching
    [□\,| (C_i[x_i] → t_i)_{i∈I}] &\;≡\; □
    \tag{if $k ∈ I ⊆_\text{fin} \mathbb{N}$,
    and $∀i∈I, (x_i, t_i) ∈ \mathcal{V}_{ι} × Λ$}\\
    % Fixpoint step
    φa.v &\;≡\; v[a := φa.v]
    \tag{if $a ∈ \mathcal{V}_{τ}$, and $v ∈ Λ_{ι}$}\\
    % Record filter
    R(\{(l_i = v_i)_{i∈I}\},t) &\;≡\; t
    \tag{if $I ⊆_\text{fin} \mathbb{N}$, $t ∈ Λ$, and $∀i∈I, v_i ∈ Λ_{ι}$}\\
    % Delta reduction
    δ(v,w,t) &\;≡\; t
    \tag{if $t ∈ Λ$, and $v, w ∈ Λ_{ι}$ with $v ≡ w$}
  \end{align*}
  %
  Derived equivalences
  \begin{align*}
    % η-reduction
    λx.t\;x &\;≡\; t
    \tag{if $x ∈ \mathcal{F}_{ι}$, $t ∈ Λ$, and $x ∉ FV(t)$}\\
    % Elimination of μ-abstraction
    μα.t &\;≡\; t
    \tag{if $α ∈ \mathcal{F}_{σ}$, $t ∈ Λ$, and $α ∉ FV(t)$}\\
    % Contraction of μ-abstractions
    μα.μβ.t &\;≡\; μα.t[β := α]
    \tag{if $α, β ∈ \mathcal{F}_{σ}$, and $t ∈ Λ$}\\
  \end{align*}
  %
  Distinguishable terms (inequivalences)
  %
  \caption{Axiomatization of observational equivalence}
  \label{fig:axiomatization_equiv}.
\end{figure}

% TODO

\section{Canonical values}

% TODO
